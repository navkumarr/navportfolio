As students, ChatGPT and other AI chatbots have revolutionized how many of us handle and process new information given to us. While many of us are cognizant of how inaccurate these models are, as was discussed in the Artificial Intelligence Forum held by the Wisconsin Business Review last fall, the models’ ability to present things to us how we want them has helped many of us streamline our college education.

However, this ability to present information however an AI model is directed to can, and often is, used for much more detrimental purposes. 

Recently, before the New Hampshire primaries, a robocall went out to many New Hampshire voters [imitating Joe Biden’s voice](https://apnews.com/article/new-hampshire-primary-biden-ai-deepfake-robocall-f3469ceb6dd613079092287994663db5). It told voters not to vote in New Hampshire’s primaries and that their “vote makes a difference in November, not this Tuesday.” The call was, strangely, made from the phone number of Kathy Sullivan, the former Democratic Party chair for the state of New Hampshire. 

This went directly against the state Democratic Party’s push for voters to write-in Biden’s name on to primary votes as his name was not on the primary ballot in the state. [Biden ultimately won](https://www.politico.com/news/2024/01/23/biden-new-hampshire-write-in-win-00137418) with ease over Dean Phillips (D-MN), who is still campaigning to win the nomination over Joe Biden by the Democratic Party.

There are many conflicting opinions on who was behind the mass robocall, but ultimately, *who did it* doesn’t matter more than the message such an act sends.

The first and most pressing theme this situation displays is the utter lack of preparedness our government has in response to the increasing amount of cybercrimes powered by artificial intelligence. Though our governmental system was purposefully designed to stop legislation from being passed without extensive deliberation by all interested parties, the extremely slow pace at which this deliberation is conducted almost negates the positive effects that the legislation can have in relation to quickly-changing technology.

In other words, AI is being developed so quickly that its application and abilities just a few years ago pale in comparison to what it is capable of today, and thus it is very difficult to regulate through the proper channels; very few people could have predicted in 2020 during the crypto-boom that within just three years the entire tech industry would be upheaved by the “AI Revolution”.

Thus, the federal government now has to rely on quick legislation in the form of executive orders, which were originally designed to be used only in emergency situations, to limit the negative impact of this technology. Subsequently, in the days following the New Hampshire ordeal until now, President Biden and the Democratic Party as a whole have been working on writing what is likely to be the first [executive order of 2024](https://www.whitehouse.gov/briefing-room/statements-releases/2024/01/29/fact-sheet-biden-harris-administration-announces-key-ai-actions-following-president-bidens-landmark-executive-order/).

This order will increase regulation against AI in relation to national security, and orient the technology to be used for good within the education and public infrastructure system.

Though it is necessary for President Biden and others to pass this order, the fact that it can only realistically be done through executive orders is telling of how unprepared our system is in fighting modern issues.

Another theme that underlies the New Hampshire robocalls is that people are scared of AI, but don’t know exactly what *about* AI makes them so afraid. 

According to the [Pew Research Center](https://www.pewresearch.org/short-reads/2023/08/28/growing-public-concern-about-the-role-of-artificial-intelligence-in-daily-life/), 52 percent of Americans are more concerned than excited about the use of artificial intelligence in their daily lives. However, when respondents were asked about whether they were excited or concerned about specific applications of AI in their daily lives, an average of \~ 41 percent responded that they were “not sure”. 

While the robocalls exemplified one of the more unethical uses of artificial intelligence, the widespread hysteria of AI is unfounded. Due to such stories as the Biden robocall incident being the ones that gain national attention, perspectives of AI may change when considering the wide range of positive applications it can have in our lives.

As aforementioned, I use AI every day to learn and review course material in a way that makes sense to me. Using ChatGPT and Google Bard, I ask questions that give me easy-to-understand answers. While I notably *do not* use AI to replace lectures or skip reading, I use it in a way that allows me to better deliberate information when I am already grappling with it, and this gives me a deeper understanding of course material which is my ultimate goal in college.

I also use AI to help me flesh out my ideas and proofread my writing; I even used ChatGPT as a set of eyes to proofread this article.

Some consider such implementation of AI into people’s workflow as lazy and cause for concern instead of excitement, but this couldn’t be further from the truth. While there are definitely a small number of people who use AI to do their work and think critically for them, this is, in my experience, a small minority of AI users overall. 

Personally, (as someone whose job is based almost wholly on relaying and analyzing the applications of AI in our daily lives) I have **never** met someone who uses AI for any other purpose but to help them complete their tasks more effectively and efficiently. Ultimately, most people’s only goal is to live a more fulfilling life and AI helps them do just that.

This is not to say that there isn’t a great cause for concern over the “AI Revolution”, but it is important to tailor the negative with the unspoken positives that this technology provides us. 

As such, I fall somewhere between being more excited or concerned about artificial intelligence’s role in our daily lives. Though I am cognizant that the technology is being used in harmful ways, such as what took place in New Hampshire, I also recognize how much it has helped myself and many others. 

Thus, while it is necessary for our slow-moving government to properly address the concerns of AI through effective legislation, it is also necessary for Americans as a whole to know what exactly they fear, and realize that AI is much more than the negative stories being told about it nationwide.  
